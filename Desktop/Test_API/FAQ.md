# ‚ùì FAQ - Les 4 Killer Features de TGR API v2.0

---

## Q1: C'est quoi la d√©tection d'anomalies exactement?

**A:** Votre IA scanne le **PASS√â** pour trouver des d√©penses anormales.

Pour chaque mois dans l'historique:
1. Elle r√©cup√®re la d√©pense **r√©elle**
2. Elle pr√©pdit ce qu'elle **aurait d√ª √™tre** (selon le mod√®le SARIMA)
3. Elle calcule l'**√©cart** entre r√©el et pr√©dit
4. Si l'√©cart d√©passe **2 √©carts-types** ‚Üí **ANOMALIE** üö®

**Exemple r√©el**:
- Mars 2023: D√©pense r√©elle = 5M DH
- Mod√®le pr√©dit: 3M DH (normal)
- √âcart: 2M DH (67% de plus!)
- S√©v√©rit√©: **HIGH** ‚Üí √Ä auditer

---

## Q2: Comment √ßa √©conomise du temps √† la TGR?

**A:** Sans ma solution, l'audit manuel:
- Scan tous les mois = 12+ heures/mois
- Humain = erreurs et fatigue
- Rapports manuels = retards

Avec la solution:
- ‚úÖ Automatique, instantan√© (~0.5 sec/fichier)
- ‚úÖ Impossible de rater une anomalie
- ‚úÖ Rapport JSON pr√™t export/traitement
- ‚úÖ Historique complet pour compliance

**ROI**: R√©cup√®re ~10h/mois = 120h/an = üìà productivit√©

---

## Q3: Les donn√©es sont persist√©es o√π?

**A:** Deux options selon l'environnement:

**D√©veloppement local:**
- Fichier: `tgr_api.db` (SQLite)
- O√π: Dossier de l'API
- Taille: MB (petit)
- Requ√™te: Direct, rapide
- Backup: Copier le fichier

**Production:**
- BD: PostgreSQL sur serveur
- O√π: `/var/lib/postgresql/data` (volume Docker)
- Taille: GB+ (scalable)
- Requ√™te: R√©seau optimis√©
- Backup: `pg_dump` automatis√©

**Structure de donn√©es:**
```
Users (cl√©s API)
  ‚îú‚îÄ Files (fichiers upload√©s)
  ‚îú‚îÄ Predictions (r√©sultats)
  ‚îî‚îÄ Anomalies (anormalit√©s d√©tect√©es)
```

---

## Q4: Comment la qualit√© du code aide?

**A:** Trois niveaux:

1. **Pour le d√©veloppement:**
   - Black = pas de d√©bat sur style
   - MyPy = d√©tecte erreurs types AVANT run
   - R√©sultat: Code lisible, maintenable

2. **Pour la production:**
   - Bugs r√©duits = stabilit√© API
   - Performance optimis√©e
   - S√©curit√©: Moins de vuln√©rabilit√©s

3. **Pour la conformit√©:**
   - TGR veut du code professionnel
   - Black + MyPy = "Google quality"
   - Facile √† auditer pour compliance

---

## Q5: C'est quoi GPU, CPU? Je dois en acheter?

**A:** **NON, vous n'avez PAS besoin.**

- **CPU** (actuel): Suffisant pour SARIMA + d√©tection anomalies
- **GPU**: Utile seulement plus tard (mod√®les Deep Learning)

Performances actuelles:
- Fichier 50k lignes = 2-3 sec
- 1000 requ√™tes/jour = np probl√®me
- Consomme 500MB RAM

---

## Q6: GitHub Actions, c'est compliqu√© √† configurer?

**A:** **NON, c'est 5 minutes:**

1. Push votre code vers GitHub
2. Aller dans `Settings ‚Üí Secrets`
3. Ajouter 5 secrets (Docker credentials, SSH keys)
4. C'est tout! ü™Ñ

√Ä partir du push suivant:
- Lint automatique ‚úÖ
- Tests automatiques ‚úÖ
- Build Docker ‚úÖ
- Deploy production ‚úÖ

---

## Q7: Peut-je revenir √† v1.2 si quelque chose casse?

**A:** **OUI, facile:**

```bash
# Voir versions disponibles
git tag

# Revenir √† v1.2
git checkout v1.2.0

# Ou via git log
git log --oneline
git checkout <commit-hash>
```

Mais c'est **tr√®s peu probable** que √ßa casse:
- ‚úÖ Tests passent
- ‚úÖ CI/CD valide tout
- ‚úÖ Backward compatible (juste des ajouts)

---

## Q8: Combien √ßa co√ªte en infrastructure?

**A:** **Tr√®s peu:**

**D√©veloppement local**: $0
- Votre laptop suffit

**Staging**: ~$20-30/mois
- Small server + small PostgreSQL

**Production**: ~$50-100/mois
- Medium server (2 vCPU, 4GB RAM)
- PostgreSQL 100GB
- Backup automatis√©

**Sans les 4 features**: M√™me co√ªt, mais moins de valeur.

---

## Q9: Je dois changer mon code existant?

**A:** **NON, 0% changement.**

Les 4 features sont **additifs**:
- ‚úÖ D√©tection anomalies = nouvelle m√©thode, auto-appel√©e
- ‚úÖ BD = endpoints s√©par√©s, optionnels
- ‚úÖ Black/MyPy = juste config, pas de code change
- ‚úÖ CI/CD = workflow GitHub, z√©ro code

Votre API v1.2 fonctionne exactement pareil:
- `/predict` ‚Üí marche + retourne anomalies bonus
- `/health` ‚Üí pareil
- `/docs` ‚Üí pareil

---

## Q10: Quelle est la prochaine √©tape?

**A:** Recommandations prioritaires:

**Semaine 1:**
1. Lire `QUICKSTART.md`
2. Lancer local: `uvicorn main:app --reload`
3. Tester `/predict` + voir anomalies
4. Tester `/api/db` endpoints

**Semaine 2-3:**
1. Tester avec donn√©es r√©elles TGR
2. Valider d√©tection anomalies
3. Setup GitHub repo
4. Configurer CI/CD (ajouter secrets)

**Mois 1-2:**
1. Deploy staging
2. QA testing
3. Docs utilisateurs
4. Formation √©quipe TGR

**Mois 3+:**
1. Consid√©rer Deep Learning (optional)
2. Dashboard admin si besoin
3. Alertes temps r√©el si utile

---

## Q11: Qui maintient le code apr√®s livraison?

**A:** **Vous!** Mais c'est facile:

**Maintenance quotidienne:**
- 0 heures (tout est automatis√©)

**Maintenance mensuelle:**
- ~1h : V√©rifier logs, anomalies √©lev√©es
- ~1h : Backup BD

**Maintenance trimestrielle:**
- ~4h : Update d√©pendances, security patches

**√Ä long terme:**
- Consid√©rer Phase 2 (Deep Learning, etc.)

Co√ªt total: ~10-15h/trimestre = tr√®s g√©rable.

---

## Q12: Et pour la scaling? Si TGR a 1000000 requ√™tes/jour?

**A:** **Architecture est pr√™te pour scaling:**

**Actuellement** (v2.0):
- 1 serveur = ~10k req/jour
- Suffisant pour TGR v1

**Si besoin escalade:**
- Docker Swarm / Kubernetes
- Load balancer (Nginx) + N instances
- Managed PostgreSQL (RDS, Aiven)
- C2 (CDN) pour frontends

Co√ªt passe √† $200-500/mois, mais valeur explose.

---

## Q13: Les donn√©es sont s√©curis√©es?

**A:** **OUI**, 3 niveaux:

1. **Authentification:**
   - API Key (X-API-Key header)
   - Validation stricte
   - Reject sans cl√© ‚Üí 401

2. **Transport:**
   - HTTPS (SSL/TLS)
   - Nginx reverse proxy
   - Firewall

3. **Stockage:**
   - BD localis√©e (ne sort pas du serveur)
   - Backups chiffr√©s
   - Logs d'acc√®s pour audit

**Recommendation:** Ajouter OAuth2 pour v2.1 pour extra s√©curit√©.

---

## Q14: Comment j'exporte les anomalies pour un rapport?

**A:** Plusieurs options:

**Option 1: JSON brut**
```bash
curl "http://localhost:8000/api/db/anomalies/list?api_key=XXX" > anomalies.json
```

**Option 2: CSV (bash)**
```bash
curl -s "http://localhost:8000/api/db/anomalies/list?api_key=XXX" | \
  jq -r '.anomalies[] | [.date, .severity, .residual] | @csv' > anomalies.csv
```

**Option 3: Dashboard (future)**
- v2.1 ajoutera Streamlit dashboard avec export PDF

---

## Q15: Je peux tester avec l'API avant d√©ploiement?

**A:** **Bien s√ªr! √âtapes:**

1. **Lancer local:**
```bash
uvicorn main:app --reload
```

2. **Swagger UI interactive:**
```
http://localhost:8000/docs
```
Cliquer, fill forms, test directement.

3. **Ou via curl:**
```bash
# Register
API_KEY=$(curl -s -X POST http://localhost:8000/api/db/users/register?organization=Test | jq -r '.api_key')

# Predict
curl -X POST http://localhost:8000/predict \
  -H "X-API-Key: $API_KEY" \
  -F "file=@test.csv"
```

**0 risque**, totalement sandbox√©.

---

## üéì SUMMARY

| Question | R√©ponse |
|----------|---------|
| Anomalies d√©tect√©es? | ‚úÖ Auto via r√©sidus SARIMA |
| Donn√©es persist√©es? | ‚úÖ SQLite/PostgreSQL |
| Code qualit√©? | ‚úÖ Black + MyPy (0 erreurs) |
| CI/CD automatis√©? | ‚úÖ GitHub Actions |
| Co√ªte cher? | ‚ùå $0-100/mois selon scale |
| Faut changer code? | ‚ùå 0% modification |
| Pr√™t production? | ‚úÖ Yes! |

---

**Autres questions?** Consulter:
- [KILLER_FEATURES_GUIDE.md](KILLER_FEATURES_GUIDE.md)
- [QUICKSTART.md](QUICKSTART.md)
- [DEPLOYMENT.md](DEPLOYMENT.md)
- Swagger UI: http://localhost:8000/docs

**Happy coding!** üöÄ
```
